{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2502bd9f-845f-4007-b617-fa17e2a58d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import tempfile\n",
    "\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "# import tensorflow_datasets as tfds #relevant to pip3 install tf-models-official\n",
    "\n",
    "tf.print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6486853e-ba89-4847-beba-2ef043550e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ai_benchmark import AIBenchmark\n",
    "# benchmark = AIBenchmark(use_CPU=False, verbose_level=1)\n",
    "# results = benchmark.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ca27c7cf",
   "metadata": {},
   "source": [
    "notion!! this notebook is try to reproduce [ Object detection with Model Garden](https://www.tensorflow.org/tfmodels/vision/object_detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28f18ed-3271-4aa8-9726-bfb952dc388a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import pprint\n",
    "import tempfile\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from six import BytesIO\n",
    "from IPython import display\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9a11cc-e5b9-4b7a-ae21-efb56a15322c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import orbit\n",
    "import tensorflow_models as tfm\n",
    "\n",
    "from official.core import exp_factory\n",
    "from official.core import config_definitions as cfg\n",
    "from official.vision.serving import export_saved_model_lib\n",
    "from official.vision.ops.preprocess_ops import normalize_image\n",
    "from official.vision.ops.preprocess_ops import resize_and_crop_image\n",
    "from official.vision.utils.object_detection import visualization_utils\n",
    "from official.vision.dataloaders.tf_example_decoder import TfExampleDecoder\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4) # Set Pretty Print Indentation\n",
    "print(tf.__version__) # Check the version of tensorflow used\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "77519cb3",
   "metadata": {},
   "source": [
    "## Configure the Retinanet Resnet FPN COCO model for custom dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4c4320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_input_path = 'bccd_coco_tfrecords/train-00000-of-00001.tfrecord'\n",
    "# valid_data_input_path = 'bccd_coco_tfrecords/valid-00000-of-00001.tfrecord'\n",
    "# test_data_input_path = 'bccd_coco_tfrecords/test-00000-of-00001.tfrecord'\n",
    "# model_dir = 'trained_model/'\n",
    "# export_dir ='exported_model/'\n",
    "\n",
    "train_data_input_path = '../bccd_coco_tfrecords/train-00000-of-00001.tfrecord'\n",
    "valid_data_input_path = '../bccd_coco_tfrecords/valid-00000-of-00001.tfrecord'\n",
    "test_data_input_path = '../bccd_coco_tfrecords/test-00000-of-00001.tfrecord'\n",
    "model_dir = '../trained_model/'\n",
    "export_dir ='../exported_model/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2bd830",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_config = exp_factory.get_exp_config('retinanet_resnetfpn_coco')\n",
    "\n",
    "batch_size = 8\n",
    "num_classes = 3\n",
    "\n",
    "HEIGHT, WIDTH = 256, 256\n",
    "IMG_SIZE = [HEIGHT, WIDTH, 3]\n",
    "\n",
    "# Backbone config.\n",
    "exp_config.task.freeze_backbone = False\n",
    "exp_config.task.annotation_file = ''\n",
    "\n",
    "# Model config.\n",
    "exp_config.task.model.input_size = IMG_SIZE\n",
    "exp_config.task.model.num_classes = num_classes + 1\n",
    "exp_config.task.model.detection_generator.tflite_post_processing.max_classes_per_detection = exp_config.task.model.num_classes\n",
    "\n",
    "# Training data config.\n",
    "exp_config.task.train_data.input_path = train_data_input_path\n",
    "exp_config.task.train_data.dtype = 'float32'\n",
    "exp_config.task.train_data.global_batch_size = batch_size\n",
    "exp_config.task.train_data.parser.aug_scale_max = 1.0\n",
    "exp_config.task.train_data.parser.aug_scale_min = 1.0\n",
    "\n",
    "# Validation data config.\n",
    "exp_config.task.validation_data.input_path = valid_data_input_path\n",
    "exp_config.task.validation_data.dtype = 'float32'\n",
    "exp_config.task.validation_data.global_batch_size = batch_size\n",
    "\n",
    "#--------------------------------------------\n",
    "logical_device_names = [logical_device.name for logical_device in tf.config.list_logical_devices()]\n",
    "\n",
    "if 'GPU' in ''.join(logical_device_names):\n",
    "  print('This may be broken in Colab.')\n",
    "  device = 'GPU'\n",
    "elif 'TPU' in ''.join(logical_device_names):\n",
    "  print('This may be broken in Colab.')\n",
    "  device = 'TPU'\n",
    "else:\n",
    "  print('Running on CPU is slow, so only train for a few steps.')\n",
    "  device = 'CPU'\n",
    "\n",
    "\n",
    "train_steps = 1000\n",
    "exp_config.trainer.steps_per_loop = 100 # steps_per_loop = num_of_training_examples // train_batch_size\n",
    "\n",
    "exp_config.trainer.summary_interval = 100\n",
    "exp_config.trainer.checkpoint_interval = 100\n",
    "exp_config.trainer.validation_interval = 100\n",
    "exp_config.trainer.validation_steps =  100 # validation_steps = num_of_validation_examples // eval_batch_size\n",
    "exp_config.trainer.train_steps = train_steps\n",
    "exp_config.trainer.optimizer_config.warmup.linear.warmup_steps = 100\n",
    "exp_config.trainer.optimizer_config.learning_rate.type = 'cosine'\n",
    "exp_config.trainer.optimizer_config.learning_rate.cosine.decay_steps = train_steps\n",
    "exp_config.trainer.optimizer_config.learning_rate.cosine.initial_learning_rate = 0.1\n",
    "exp_config.trainer.optimizer_config.warmup.linear.warmup_learning_rate = 0.05\n",
    "\n",
    "#print rst\n",
    "pp.pprint(exp_config.as_dict())\n",
    "# display.Javascript('google.colab.output.setIframeHeight(\"500px\");')\n",
    "\n",
    "# distribution strategy\n",
    "if exp_config.runtime.mixed_precision_dtype == tf.float16:\n",
    "    tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "if 'GPU' in ''.join(logical_device_names):\n",
    "  distribution_strategy = tf.distribute.MirroredStrategy()\n",
    "elif 'TPU' in ''.join(logical_device_names):\n",
    "  tf.tpu.experimental.initialize_tpu_system()\n",
    "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='/device:TPU_SYSTEM:0')\n",
    "  distribution_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "  print('Warning: this will be really slow.')\n",
    "  distribution_strategy = tf.distribute.OneDeviceStrategy(logical_device_names[0])\n",
    "\n",
    "print('Done')\n",
    "\n",
    "# Create the Task object \n",
    "with distribution_strategy.scope():\n",
    "  task = tfm.core.task_factory.get_task(exp_config.task, logging_dir=model_dir)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2cb84118",
   "metadata": {},
   "source": [
    "## Visualize a batch of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e8ee01",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in task.build_inputs(exp_config.task.train_data).take(1):\n",
    "  print()\n",
    "  print(f'images.shape: {str(images.shape):16}  images.dtype: {images.dtype!r}')\n",
    "  print(f'labels.keys: {labels.keys()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dbfd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_index={\n",
    "    1: {\n",
    "        'id': 1,\n",
    "        'name': 'Platelets'\n",
    "       },\n",
    "    2: {\n",
    "        'id': 2,\n",
    "        'name': 'RBC'\n",
    "       },\n",
    "    3: {\n",
    "        'id': 3,\n",
    "        'name': 'WBC'\n",
    "       }\n",
    "}\n",
    "tf_ex_decoder = TfExampleDecoder()\n",
    "\n",
    "\n",
    "def show_batch(raw_records, num_of_examples):\n",
    "  plt.figure(figsize=(20, 20))\n",
    "  use_normalized_coordinates=True\n",
    "  min_score_thresh = 0.30\n",
    "  for i, serialized_example in enumerate(raw_records):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    decoded_tensors = tf_ex_decoder.decode(serialized_example)\n",
    "    image = decoded_tensors['image'].numpy().astype('uint8')\n",
    "    scores = np.ones(shape=(len(decoded_tensors['groundtruth_boxes'])))\n",
    "    visualization_utils.visualize_boxes_and_labels_on_image_array(\n",
    "        image,\n",
    "        decoded_tensors['groundtruth_boxes'].numpy(),\n",
    "        decoded_tensors['groundtruth_classes'].numpy().astype('int'),\n",
    "        scores,\n",
    "        category_index=category_index,\n",
    "        use_normalized_coordinates=use_normalized_coordinates,\n",
    "        max_boxes_to_draw=200,\n",
    "        min_score_thresh=min_score_thresh,\n",
    "        agnostic_mode=False,\n",
    "        instance_masks=None,\n",
    "        line_thickness=4)\n",
    "\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Image-{i+1}')\n",
    "  plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b979c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_size = 20\n",
    "num_of_examples = 3\n",
    "\n",
    "raw_records = tf.data.TFRecordDataset(\n",
    "    exp_config.task.train_data.input_path).shuffle(\n",
    "        buffer_size=buffer_size).take(num_of_examples)\n",
    "show_batch(raw_records, num_of_examples)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "08d3b032",
   "metadata": {},
   "source": [
    "# Train and evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb88f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, eval_logs = tfm.core.train_lib.run_experiment(\n",
    "    distribution_strategy=distribution_strategy,\n",
    "    task=task,\n",
    "    mode='train_and_eval',\n",
    "    params=exp_config,\n",
    "    model_dir=model_dir,\n",
    "    run_post_eval=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a143cd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir '../trained_model/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae7083e",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_saved_model_lib.export_inference_graph(\n",
    "    input_type='image_tensor',\n",
    "    batch_size=1,\n",
    "    input_image_size=[HEIGHT, WIDTH],\n",
    "    params=exp_config,\n",
    "    checkpoint_path=tf.train.latest_checkpoint(model_dir),\n",
    "    export_dir=export_dir)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6ed0a701",
   "metadata": {},
   "source": [
    "# inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f27f178",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(path):\n",
    "  \"\"\"Load an image from file into a numpy array.\n",
    "\n",
    "  Puts image into numpy array to feed into tensorflow graph.\n",
    "  Note that by convention we put it into a numpy array with shape\n",
    "  (height, width, channels), where channels=3 for RGB.\n",
    "\n",
    "  Args:\n",
    "    path: the file path to the image\n",
    "\n",
    "  Returns:\n",
    "    uint8 numpy array with shape (img_height, img_width, 3)\n",
    "  \"\"\"\n",
    "  image = None\n",
    "  if(path.startswith('http')):\n",
    "    response = urlopen(path)\n",
    "    image_data = response.read()\n",
    "    image_data = BytesIO(image_data)\n",
    "    image = Image.open(image_data)\n",
    "  else:\n",
    "    image_data = tf.io.gfile.GFile(path, 'rb').read()\n",
    "    image = Image.open(BytesIO(image_data))\n",
    "\n",
    "  (im_width, im_height) = image.size\n",
    "  return np.array(image.getdata()).reshape(\n",
    "      (1, im_height, im_width, 3)).astype(np.uint8)\n",
    "\n",
    "\n",
    "\n",
    "def build_inputs_for_object_detection(image, input_image_size):\n",
    "  \"\"\"Builds Object Detection model inputs for serving.\"\"\"\n",
    "  image, _ = resize_and_crop_image(\n",
    "      image,\n",
    "      input_image_size,\n",
    "      padded_size=input_image_size,\n",
    "      aug_scale_min=1.0,\n",
    "      aug_scale_max=1.0)\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac07177b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_examples = 3\n",
    "\n",
    "test_ds = tf.data.TFRecordDataset(\n",
    "    '../bccd_coco_tfrecords/test-00000-of-00001.tfrecord').take(\n",
    "        num_of_examples)\n",
    "show_batch(test_ds, num_of_examples)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "59f5c2f7",
   "metadata": {},
   "source": [
    "## predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992ed146",
   "metadata": {},
   "outputs": [],
   "source": [
    "imported = tf.saved_model.load(export_dir)\n",
    "model_fn = imported.signatures['serving_default']\n",
    "\n",
    "input_image_size = (HEIGHT, WIDTH)\n",
    "plt.figure(figsize=(20, 20))\n",
    "min_score_thresh = 0.30 # Change minimum score for threshold to see all bounding boxes confidences.\n",
    "\n",
    "for i, serialized_example in enumerate(test_ds):\n",
    "  plt.subplot(1, 3, i+1)\n",
    "  decoded_tensors = tf_ex_decoder.decode(serialized_example)\n",
    "  image = build_inputs_for_object_detection(decoded_tensors['image'], input_image_size)\n",
    "  image = tf.expand_dims(image, axis=0)\n",
    "  image = tf.cast(image, dtype = tf.uint8)\n",
    "  image_np = image[0].numpy()\n",
    "  result = model_fn(image)\n",
    "  visualization_utils.visualize_boxes_and_labels_on_image_array(\n",
    "      image_np,\n",
    "      result['detection_boxes'][0].numpy(),\n",
    "      result['detection_classes'][0].numpy().astype(int),\n",
    "      result['detection_scores'][0].numpy(),\n",
    "      category_index=category_index,\n",
    "      use_normalized_coordinates=False,\n",
    "      max_boxes_to_draw=200,\n",
    "      min_score_thresh=min_score_thresh,\n",
    "      agnostic_mode=False,\n",
    "      instance_masks=None,\n",
    "      line_thickness=4)\n",
    "  plt.imshow(image_np)\n",
    "  plt.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e19a5fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
