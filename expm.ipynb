{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2502bd9f-845f-4007-b617-fa17e2a58d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "import tempfile\n",
    "\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "# import tensorflow_datasets as tfds #relevant to pip3 install tf-models-official\n",
    "\n",
    "tf.print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6486853e-ba89-4847-beba-2ef043550e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ai_benchmark import AIBenchmark\n",
    "# benchmark = AIBenchmark(use_CPU=False, verbose_level=1)\n",
    "# results = benchmark.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ca27c7cf",
   "metadata": {},
   "source": [
    "notion!! this notebook is try to reproduce [ Object detection with Model Garden](https://www.tensorflow.org/tfmodels/vision/object_detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c28f18ed-3271-4aa8-9726-bfb952dc388a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import pprint\n",
    "import tempfile\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from six import BytesIO\n",
    "from IPython import display\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d9a11cc-e5b9-4b7a-ae21-efb56a15322c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exist\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\exist\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.1\n"
     ]
    }
   ],
   "source": [
    "import orbit\n",
    "import tensorflow_models as tfm\n",
    "\n",
    "from official.core import exp_factory\n",
    "from official.core import config_definitions as cfg\n",
    "from official.vision.serving import export_saved_model_lib\n",
    "from official.vision.ops.preprocess_ops import normalize_image\n",
    "from official.vision.ops.preprocess_ops import resize_and_crop_image\n",
    "from official.vision.utils.object_detection import visualization_utils\n",
    "from official.vision.dataloaders.tf_example_decoder import TfExampleDecoder\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4) # Set Pretty Print Indentation\n",
    "print(tf.__version__) # Check the version of tensorflow used\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "77519cb3",
   "metadata": {},
   "source": [
    "## Configure the Retinanet Resnet FPN COCO model for custom dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b4c4320",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_input_path = 'bccd_coco_tfrecords/train-00000-of-00001.tfrecord'\n",
    "valid_data_input_path = 'bccd_coco_tfrecords/valid-00000-of-00001.tfrecord'\n",
    "test_data_input_path = 'bccd_coco_tfrecords/test-00000-of-00001.tfrecord'\n",
    "model_dir = 'trained_model/'\n",
    "export_dir ='exported_model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd2bd830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on CPU is slow, so only train for a few steps.\n",
      "{   'runtime': {   'all_reduce_alg': None,\n",
      "                   'batchnorm_spatial_persistent': False,\n",
      "                   'dataset_num_private_threads': None,\n",
      "                   'default_shard_dim': -1,\n",
      "                   'distribution_strategy': 'mirrored',\n",
      "                   'enable_xla': False,\n",
      "                   'gpu_thread_mode': None,\n",
      "                   'loss_scale': None,\n",
      "                   'mixed_precision_dtype': 'bfloat16',\n",
      "                   'num_cores_per_replica': 1,\n",
      "                   'num_gpus': 0,\n",
      "                   'num_packs': 1,\n",
      "                   'per_gpu_thread_count': 0,\n",
      "                   'run_eagerly': False,\n",
      "                   'task_index': -1,\n",
      "                   'tpu': None,\n",
      "                   'tpu_enable_xla_dynamic_padder': None,\n",
      "                   'worker_hosts': None},\n",
      "    'task': {   'annotation_file': '',\n",
      "                'differential_privacy_config': None,\n",
      "                'export_config': {   'cast_detection_classes_to_float': False,\n",
      "                                     'cast_num_detections_to_float': False,\n",
      "                                     'output_normalized_coordinates': False},\n",
      "                'freeze_backbone': False,\n",
      "                'init_checkpoint': 'gs://cloud-tpu-checkpoints/vision-2.0/resnet50_imagenet/ckpt-28080',\n",
      "                'init_checkpoint_modules': 'backbone',\n",
      "                'losses': {   'box_loss_weight': 50,\n",
      "                              'focal_loss_alpha': 0.25,\n",
      "                              'focal_loss_gamma': 1.5,\n",
      "                              'huber_loss_delta': 0.1,\n",
      "                              'l2_weight_decay': 0.0001,\n",
      "                              'loss_weight': 1.0},\n",
      "                'model': {   'anchor': {   'anchor_size': 4.0,\n",
      "                                           'aspect_ratios': [0.5, 1.0, 2.0],\n",
      "                                           'num_scales': 3},\n",
      "                             'backbone': {   'resnet': {   'bn_trainable': True,\n",
      "                                                           'depth_multiplier': 1.0,\n",
      "                                                           'model_id': 50,\n",
      "                                                           'replace_stem_max_pool': False,\n",
      "                                                           'resnetd_shortcut': False,\n",
      "                                                           'scale_stem': True,\n",
      "                                                           'se_ratio': 0.0,\n",
      "                                                           'stem_type': 'v0',\n",
      "                                                           'stochastic_depth_drop_rate': 0.0},\n",
      "                                             'type': 'resnet'},\n",
      "                             'decoder': {   'fpn': {   'fusion_type': 'sum',\n",
      "                                                       'num_filters': 256,\n",
      "                                                       'use_keras_layer': False,\n",
      "                                                       'use_separable_conv': False},\n",
      "                                            'type': 'fpn'},\n",
      "                             'detection_generator': {   'apply_nms': True,\n",
      "                                                        'max_num_detections': 100,\n",
      "                                                        'nms_iou_threshold': 0.5,\n",
      "                                                        'nms_version': 'v2',\n",
      "                                                        'pre_nms_score_threshold': 0.05,\n",
      "                                                        'pre_nms_top_k': 5000,\n",
      "                                                        'soft_nms_sigma': None,\n",
      "                                                        'tflite_post_processing': {   'max_classes_per_detection': 4,\n",
      "                                                                                      'max_detections': 200,\n",
      "                                                                                      'nms_iou_threshold': 0.5,\n",
      "                                                                                      'nms_score_threshold': 0.1,\n",
      "                                                                                      'use_regular_nms': False},\n",
      "                                                        'use_cpu_nms': False},\n",
      "                             'head': {   'attribute_heads': [],\n",
      "                                         'num_convs': 4,\n",
      "                                         'num_filters': 256,\n",
      "                                         'share_classification_heads': False,\n",
      "                                         'use_separable_conv': False},\n",
      "                             'input_size': [256, 256, 3],\n",
      "                             'max_level': 7,\n",
      "                             'min_level': 3,\n",
      "                             'norm_activation': {   'activation': 'relu',\n",
      "                                                    'norm_epsilon': 0.001,\n",
      "                                                    'norm_momentum': 0.99,\n",
      "                                                    'use_sync_bn': False},\n",
      "                             'num_classes': 4},\n",
      "                'name': None,\n",
      "                'per_category_metrics': False,\n",
      "                'train_data': {   'block_length': 1,\n",
      "                                  'cache': False,\n",
      "                                  'cycle_length': None,\n",
      "                                  'decoder': {   'simple_decoder': {   'mask_binarize_threshold': None,\n",
      "                                                                       'regenerate_source_id': False},\n",
      "                                                 'type': 'simple_decoder'},\n",
      "                                  'deterministic': None,\n",
      "                                  'drop_remainder': True,\n",
      "                                  'dtype': 'float32',\n",
      "                                  'enable_tf_data_service': False,\n",
      "                                  'file_type': 'tfrecord',\n",
      "                                  'global_batch_size': 8,\n",
      "                                  'input_path': 'bccd_coco_tfrecords/train-00000-of-00001.tfrecord',\n",
      "                                  'is_training': True,\n",
      "                                  'parser': {   'aug_policy': None,\n",
      "                                                'aug_rand_hflip': True,\n",
      "                                                'aug_scale_max': 1.0,\n",
      "                                                'aug_scale_min': 1.0,\n",
      "                                                'aug_type': None,\n",
      "                                                'match_threshold': 0.5,\n",
      "                                                'max_num_instances': 100,\n",
      "                                                'num_channels': 3,\n",
      "                                                'skip_crowd_during_training': True,\n",
      "                                                'unmatched_threshold': 0.5},\n",
      "                                  'prefetch_buffer_size': None,\n",
      "                                  'seed': None,\n",
      "                                  'sharding': True,\n",
      "                                  'shuffle_buffer_size': 10000,\n",
      "                                  'tf_data_service_address': None,\n",
      "                                  'tf_data_service_job_name': None,\n",
      "                                  'tfds_as_supervised': False,\n",
      "                                  'tfds_data_dir': '',\n",
      "                                  'tfds_name': '',\n",
      "                                  'tfds_skip_decoding_feature': '',\n",
      "                                  'tfds_split': ''},\n",
      "                'use_coco_metrics': True,\n",
      "                'use_wod_metrics': False,\n",
      "                'validation_data': {   'block_length': 1,\n",
      "                                       'cache': False,\n",
      "                                       'cycle_length': None,\n",
      "                                       'decoder': {   'simple_decoder': {   'mask_binarize_threshold': None,\n",
      "                                                                            'regenerate_source_id': False},\n",
      "                                                      'type': 'simple_decoder'},\n",
      "                                       'deterministic': None,\n",
      "                                       'drop_remainder': True,\n",
      "                                       'dtype': 'float32',\n",
      "                                       'enable_tf_data_service': False,\n",
      "                                       'file_type': 'tfrecord',\n",
      "                                       'global_batch_size': 8,\n",
      "                                       'input_path': 'bccd_coco_tfrecords/valid-00000-of-00001.tfrecord',\n",
      "                                       'is_training': False,\n",
      "                                       'parser': {   'aug_policy': None,\n",
      "                                                     'aug_rand_hflip': False,\n",
      "                                                     'aug_scale_max': 1.0,\n",
      "                                                     'aug_scale_min': 1.0,\n",
      "                                                     'aug_type': None,\n",
      "                                                     'match_threshold': 0.5,\n",
      "                                                     'max_num_instances': 100,\n",
      "                                                     'num_channels': 3,\n",
      "                                                     'skip_crowd_during_training': True,\n",
      "                                                     'unmatched_threshold': 0.5},\n",
      "                                       'prefetch_buffer_size': None,\n",
      "                                       'seed': None,\n",
      "                                       'sharding': True,\n",
      "                                       'shuffle_buffer_size': 10000,\n",
      "                                       'tf_data_service_address': None,\n",
      "                                       'tf_data_service_job_name': None,\n",
      "                                       'tfds_as_supervised': False,\n",
      "                                       'tfds_data_dir': '',\n",
      "                                       'tfds_name': '',\n",
      "                                       'tfds_skip_decoding_feature': '',\n",
      "                                       'tfds_split': ''}},\n",
      "    'trainer': {   'allow_tpu_summary': False,\n",
      "                   'best_checkpoint_eval_metric': '',\n",
      "                   'best_checkpoint_export_subdir': '',\n",
      "                   'best_checkpoint_metric_comp': 'higher',\n",
      "                   'checkpoint_interval': 100,\n",
      "                   'continuous_eval_timeout': 3600,\n",
      "                   'eval_tf_function': True,\n",
      "                   'eval_tf_while_loop': False,\n",
      "                   'loss_upper_bound': 1000000.0,\n",
      "                   'max_to_keep': 5,\n",
      "                   'optimizer_config': {   'ema': None,\n",
      "                                           'learning_rate': {   'cosine': {   'alpha': 0.0,\n",
      "                                                                              'decay_steps': 1000,\n",
      "                                                                              'initial_learning_rate': 0.1,\n",
      "                                                                              'name': 'CosineDecay',\n",
      "                                                                              'offset': 0},\n",
      "                                                                'type': 'cosine'},\n",
      "                                           'optimizer': {   'sgd': {   'clipnorm': None,\n",
      "                                                                       'clipvalue': None,\n",
      "                                                                       'decay': 0.0,\n",
      "                                                                       'global_clipnorm': None,\n",
      "                                                                       'momentum': 0.9,\n",
      "                                                                       'name': 'SGD',\n",
      "                                                                       'nesterov': False},\n",
      "                                                            'type': 'sgd'},\n",
      "                                           'warmup': {   'linear': {   'name': 'linear',\n",
      "                                                                       'warmup_learning_rate': 0.05,\n",
      "                                                                       'warmup_steps': 100},\n",
      "                                                         'type': 'linear'}},\n",
      "                   'recovery_begin_steps': 0,\n",
      "                   'recovery_max_trials': 0,\n",
      "                   'steps_per_loop': 100,\n",
      "                   'summary_interval': 100,\n",
      "                   'train_steps': 1000,\n",
      "                   'train_tf_function': True,\n",
      "                   'train_tf_while_loop': True,\n",
      "                   'validation_interval': 100,\n",
      "                   'validation_steps': 100,\n",
      "                   'validation_summary_subdir': 'validation'}}\n",
      "Warning: this will be really slow.\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "exp_config = exp_factory.get_exp_config('retinanet_resnetfpn_coco')\n",
    "\n",
    "batch_size = 8\n",
    "num_classes = 3\n",
    "\n",
    "HEIGHT, WIDTH = 256, 256\n",
    "IMG_SIZE = [HEIGHT, WIDTH, 3]\n",
    "\n",
    "# Backbone config.\n",
    "exp_config.task.freeze_backbone = False\n",
    "exp_config.task.annotation_file = ''\n",
    "\n",
    "# Model config.\n",
    "exp_config.task.model.input_size = IMG_SIZE\n",
    "exp_config.task.model.num_classes = num_classes + 1\n",
    "exp_config.task.model.detection_generator.tflite_post_processing.max_classes_per_detection = exp_config.task.model.num_classes\n",
    "\n",
    "# Training data config.\n",
    "exp_config.task.train_data.input_path = train_data_input_path\n",
    "exp_config.task.train_data.dtype = 'float32'\n",
    "exp_config.task.train_data.global_batch_size = batch_size\n",
    "exp_config.task.train_data.parser.aug_scale_max = 1.0\n",
    "exp_config.task.train_data.parser.aug_scale_min = 1.0\n",
    "\n",
    "# Validation data config.\n",
    "exp_config.task.validation_data.input_path = valid_data_input_path\n",
    "exp_config.task.validation_data.dtype = 'float32'\n",
    "exp_config.task.validation_data.global_batch_size = batch_size\n",
    "\n",
    "#--------------------------------------------\n",
    "logical_device_names = [logical_device.name for logical_device in tf.config.list_logical_devices()]\n",
    "\n",
    "if 'GPU' in ''.join(logical_device_names):\n",
    "  print('This may be broken in Colab.')\n",
    "  device = 'GPU'\n",
    "elif 'TPU' in ''.join(logical_device_names):\n",
    "  print('This may be broken in Colab.')\n",
    "  device = 'TPU'\n",
    "else:\n",
    "  print('Running on CPU is slow, so only train for a few steps.')\n",
    "  device = 'CPU'\n",
    "\n",
    "\n",
    "train_steps = 1000\n",
    "exp_config.trainer.steps_per_loop = 100 # steps_per_loop = num_of_training_examples // train_batch_size\n",
    "\n",
    "exp_config.trainer.summary_interval = 100\n",
    "exp_config.trainer.checkpoint_interval = 100\n",
    "exp_config.trainer.validation_interval = 100\n",
    "exp_config.trainer.validation_steps =  100 # validation_steps = num_of_validation_examples // eval_batch_size\n",
    "exp_config.trainer.train_steps = train_steps\n",
    "exp_config.trainer.optimizer_config.warmup.linear.warmup_steps = 100\n",
    "exp_config.trainer.optimizer_config.learning_rate.type = 'cosine'\n",
    "exp_config.trainer.optimizer_config.learning_rate.cosine.decay_steps = train_steps\n",
    "exp_config.trainer.optimizer_config.learning_rate.cosine.initial_learning_rate = 0.1\n",
    "exp_config.trainer.optimizer_config.warmup.linear.warmup_learning_rate = 0.05\n",
    "\n",
    "#print rst\n",
    "pp.pprint(exp_config.as_dict())\n",
    "# display.Javascript('google.colab.output.setIframeHeight(\"500px\");')\n",
    "\n",
    "# distribution strategy\n",
    "if exp_config.runtime.mixed_precision_dtype == tf.float16:\n",
    "    tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "if 'GPU' in ''.join(logical_device_names):\n",
    "  distribution_strategy = tf.distribute.MirroredStrategy()\n",
    "elif 'TPU' in ''.join(logical_device_names):\n",
    "  tf.tpu.experimental.initialize_tpu_system()\n",
    "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='/device:TPU_SYSTEM:0')\n",
    "  distribution_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "  print('Warning: this will be really slow.')\n",
    "  distribution_strategy = tf.distribute.OneDeviceStrategy(logical_device_names[0])\n",
    "\n",
    "print('Done')\n",
    "\n",
    "# Create the Task object \n",
    "with distribution_strategy.scope():\n",
    "  task = tfm.core.task_factory.get_task(exp_config.task, logging_dir=model_dir)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2cb84118",
   "metadata": {},
   "source": [
    "## Visualize a batch of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66e8ee01",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xa8 in position 208: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfor\u001b[39;00m images, labels \u001b[39min\u001b[39;00m task\u001b[39m.\u001b[39mbuild_inputs(exp_config\u001b[39m.\u001b[39mtask\u001b[39m.\u001b[39mtrain_data)\u001b[39m.\u001b[39mtake(\u001b[39m1\u001b[39m):\n\u001b[0;32m      2\u001b[0m   \u001b[39mprint\u001b[39m()\n\u001b[0;32m      3\u001b[0m   \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mimages.shape: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(images\u001b[39m.\u001b[39mshape)\u001b[39m:\u001b[39;00m\u001b[39m16\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m  images.dtype: \u001b[39m\u001b[39m{\u001b[39;00mimages\u001b[39m.\u001b[39mdtype\u001b[39m!r}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:766\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    764\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    765\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 766\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_internal()\n\u001b[0;32m    767\u001b[0m   \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mOutOfRangeError:\n\u001b[0;32m    768\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:749\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    746\u001b[0m \u001b[39m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[39m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[39mwith\u001b[39;00m context\u001b[39m.\u001b[39mexecution_mode(context\u001b[39m.\u001b[39mSYNC):\n\u001b[1;32m--> 749\u001b[0m   ret \u001b[39m=\u001b[39m gen_dataset_ops\u001b[39m.\u001b[39;49miterator_get_next(\n\u001b[0;32m    750\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_iterator_resource,\n\u001b[0;32m    751\u001b[0m       output_types\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_output_types,\n\u001b[0;32m    752\u001b[0m       output_shapes\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_output_shapes)\n\u001b[0;32m    754\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    755\u001b[0m     \u001b[39m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[0;32m    756\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_element_spec\u001b[39m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3038\u001b[0m, in \u001b[0;36miterator_get_next\u001b[1;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m   3036\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[0;32m   3037\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3038\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[0;32m   3039\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mIteratorGetNext\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, iterator, \u001b[39m\"\u001b[39;49m\u001b[39moutput_types\u001b[39;49m\u001b[39m\"\u001b[39;49m, output_types,\n\u001b[0;32m   3040\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39moutput_shapes\u001b[39;49m\u001b[39m\"\u001b[39;49m, output_shapes)\n\u001b[0;32m   3041\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[0;32m   3042\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xa8 in position 208: invalid start byte"
     ]
    }
   ],
   "source": [
    "for images, labels in task.build_inputs(exp_config.task.train_data).take(1):\n",
    "  print()\n",
    "  print(f'images.shape: {str(images.shape):16}  images.dtype: {images.dtype!r}')\n",
    "  print(f'labels.keys: {labels.keys()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
